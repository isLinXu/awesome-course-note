# Lecture5

这份文档是哈佛大学CS197课程的第五讲笔记，主题为“AI Research Experiences”，由Pranav Rajpurkar主讲。以下是对文档内容的详细解释和分析，以及相应的课程笔记。

### 课程概述
- **目标**：通过阅读和解析代码来学习，特别是使用Vision Transformers进行图像分类的工作流程。
- **工具**：使用Lightning（PyTorch Lightning）框架。
- **内容**：涵盖数据加载、图像的tokenization处理，以及构建训练工作流程。

### 学习成果
- **数据加载和tokenization**：探索Vision Transformers的图像数据加载和tokenization。
- **PyTorch架构**：解析构建Vision Transformer的PyTorch架构和模块。
- **训练工作流程**：熟悉使用PyTorch Lightning的示例训练工作流程。

### 微调Vision Transformer
- **领域转换**：从自然语言处理转到计算机视觉，专注于图像分类。
- **类别**：识别图像属于以下10个类别中的哪一个：飞机、汽车、鸟类、猫、鹿、狗、青蛙、马、船和卡车。

### Lightning框架
- **PyTorch Lightning**：一个高层次的框架，用于组织代码，移除样板代码，并抽象出规模所需的工程复杂性。
- **安装**：使用conda和pip安装必要的库。

### 代码解析
- **数据加载**：使用CIFAR10数据集，应用不同的转换进行数据增强。
- **可视化**：展示如何可视化数据集中的图像。
- **DataLoader**：允许按批次迭代数据集，提高性能。

### Tokenization
- **图像分割**：将图像分割成小块，作为模型的输入序列。
- **变换**：对图像进行平铺、排列和展平操作，以准备输入模型。

### 神经网络模块
- **nn.Module**：所有神经网络模块的基类，用于构建模型。
- **AttentionBlock**：包含LayerNorm、MultiheadAttention等模块的注意力块。

### Vision Transformer模块
- **嵌入层**：将输入图像映射到更高维度的特征向量。
- **MLP头部**：将输出特征向量映射到分类预测。

### Lightning Module
- **组织**：将PyTorch代码组织成计算、前向传播、优化器和调度器等部分。
- **训练循环**：包括训练、验证和测试循环。
- **Trainer类**：自动化模型训练和评估过程。

### 练习
- **数据集划分**：在应用训练和测试转换之前，先将训练数据集划分为训练集和验证集。
- **模块文档**：查找Linear、GELU、Dropout、LayerNorm和Multihead Attention的文档，并描述它们的功能。
- **代码理解**：阅读文档并解释特定代码行的功能。

### 结语
- **实践学习**：通过代码解析和实践学习AI框架和模型构建。
- **框架对比**：理解不同框架（如Huggingface的transformers库和PyTorch Lightning）之间的差异。

### 课程笔记
1. **代码阅读**：通过阅读代码学习AI框架，特别是在研究环境中常用的不熟悉的框架。
2. **图像分类**：了解如何使用Vision Transformers进行图像分类任务。
3. **Lightning框架**：学习使用PyTorch Lightning组织和简化深度学习代码。
4. **数据加载**：探索如何加载和增强计算机视觉数据集。
5. **Tokenization**：了解如何将图像分割成小块以供模型使用。
6. **神经网络模块**：学习构建自定义神经网络模块，包括注意力机制。
7. **模型构建**：构建Vision Transformer模型，包括嵌入层和MLP头部。
8. **训练工作流程**：熟悉使用Lightning Module组织训练、验证和测试循环。
9. **Trainer类**：自动化深度学习模型的训练和评估过程。
10. **练习**：通过练习加深对数据加载、模型构建和训练工作流程的理解。

通过这些笔记，学生应该能够对如何使用PyTorch Lightning和Vision Transformers进行图像分类有一个基本的了解，并能够开始应用这些工具来提高他们的AI工程技能。