# Lecture6&7

这份文档是哈佛大学CS197课程的第六和第七讲笔记，主题为“AI Research Experiences”，由Pranav Rajpurkar主讲。以下是对文档内容的详细解释和分析，以及相应的课程笔记。

### 课程概述
- **目标**：巩固对PyTorch工具包的理解，通过官方教程和练习来学习。
- **内容**：涉及张量（Tensors）、自动微分（Autograd）、神经网络（Neural Networks）和分类器训练/评估（Classifier Training/Evaluation）。

### 学习成果
- **张量操作**：在PyTorch中执行张量操作。
- **神经网络**：理解神经网络的前向和后向传播。
- **训练代码**：检测PyTorch训练代码中的常见问题。

### PyTorch练习
- **教程**：首先阅读官方PyTorch Blitz教程，然后进行练习。
- **练习**：涵盖张量、自动微分、神经网络和分类器。

### 安装
- **环境设置**：使用conda创建新的环境并安装必要的PyTorch相关包。

### 张量（Tensors）
- **概念**：张量是类似于数组和矩阵的特定数据结构，用于编码模型的输入输出和参数。
- **练习**：创建张量、执行形状操作、随机数生成、设备和数据类型查询、连接和索引操作。

### 自动微分和神经网络
- **神经网络**：由参数化的嵌套函数组成，使用PyTorch的`torch.nn`包构建。
- **训练步骤**：定义网络、迭代数据集、前向传播、计算损失、反向传播和参数更新。
- **练习**：执行模型的前向传播、损失计算、反向传播和优化器步骤。

### 分类器训练
- **CIFAR10教程**：加载和标准化CIFAR10数据集，定义卷积神经网络，定义损失函数，训练网络，测试网络。

### 常见错误
- **数据加载**：应打乱训练数据加载器，修正数据集的加载（训练集和测试集应正确加载）。
- **训练代码**：在循环中添加`optimizer.zero_grad()`，使用`loss.item()`以避免计算图内存泄漏。
- **评估代码**：使用`torch.no_grad()`包裹循环以减少内存使用，并在求和后使用`.item()`。

### 课程笔记
1. **PyTorch基础**：通过官方教程和练习学习PyTorch。
2. **张量操作**：学习创建和操作张量，包括形状更改和随机数生成。
3. **自动微分**：理解神经网络的前向和后向传播机制。
4. **神经网络训练**：练习构建简单的神经网络并进行训练。
5. **分类器评估**：学习如何加载数据集、定义网络、训练和评估分类器。
6. **常见错误**：识别并修正数据加载、训练和评估代码中的错误。
7. **实用技巧**：使用`.item()`减少内存使用，使用`torch.no_grad()`优化评估过程。

通过这些笔记，学生应该能够对PyTorch有一个基本的了解，并能够开始使用这个工具来构建和训练自己的深度学习模型。