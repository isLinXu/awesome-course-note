# Lecture7

这份PPT是关于如何确保大型语言模型（LLM）生成的响应具有可靠性和可信度的讨论，特别是在知识基础的上下文中。由Anupam Datta、John Mitchell和Ankur Taly在斯坦福大学的CS329T课程中进行。以下是对PPT内容的详细解释和分析，以及相应的课程笔记。

### 1. LLM的挑战
- **幻觉问题**：LLM可能会生成不准确或虚构的内容。
- **偏见问题**：LLM可能会生成带有偏见的内容。

### 2. 基础性（Grounding）
- **定义**：如果LLM响应中的每个声明都可以归因于知识库中的某个文档，则认为该响应是基础性的。
- **权威性**：根据不同的用例，权威性可能有所不同。

### 3. 支持基础性响应
- **知识源**：LLM需要一个知识源，可能是向量数据库或代理。
- **检索增强生成（RAGs）**：使用RAGs来提供相关问题的上下文。

### 4. 验证响应的基础性
- **RAG三元组**：考虑上下文的相关性、响应的基础性和答案的相关性。
- **查询规划**：对于更复杂的查询，生成查询计划，将查询分解为子查询，并对每个子查询执行检索。

### 5. 响应选择和重写
- **受控文本生成**：使用技术如FUDGE（未来判别控制文本生成）来生成更可能基础的响应。
- **响应修订**：要求LLM在提供有关基础性的反馈时重写响应。

### 6. 自我一致性
- **假设**：如果所有top-k采样响应都支持的声明更可能是事实性的。
- **方法**：使用NLI模型检查采样响应中的声明的自我一致性。

### 7. 回应验证
- **断言分解**：将响应分解为声明并针对知识库进行核实。
- **NLI模型**：使用自然语言推理模型来比较响应（假设）和上下文（前提）。

### 8. 回应验证的工作流程
- **句子提取器**：从LLM响应中提取句子。
- **NLI模型**：为每个句子生成报告，包括得分和引用。

### 9. 回应验证的挑战
- **精确度问题**：不需要验证的句子可能获得高的NLI分数。
- **召回率问题**：单个句子中的多个声明可能没有被单个来源证实。

### 10. 回应验证的改进
- **动态上下文**：提供额外的“上下文”输入给NLI。
- **自我一致性**：检查声明是否在多个响应中一致。

### 11. 回应选择
- **采样**：从LLM中采样多个响应，并选择具有最高基础分数的响应。

### 12. 回应修订
- **反馈**：向LLM提供反馈，突出显示哪些句子/声明是无基础的。

### 课程笔记总结
- **LLM挑战**：了解LLM可能生成不准确或有偏见的内容的问题。
- **基础性**：学习如何定义和实现LLM响应的基础性。
- **支持基础性响应**：探索使用RAGs和查询规划来支持基础性响应。
- **验证响应**：学习如何通过断言分解和NLI模型来验证响应的基础性。
- **回应验证工作流**：了解如何为LLM响应生成报告，包括得分和引用。
- **回应验证挑战**：认识到回应验证过程中可能遇到的精确度和召回率问题。
- **回应验证改进**：学习如何通过动态上下文和自我一致性来改进回应验证。
- **回应选择**：了解如何通过采样和选择具有最高基础分数的响应来改进LLM的输出。
- **回应修订**：探索如何通过提供反馈来修订LLM的响应。

这份PPT提供了对确保LLM生成的响应具有可靠性和可信度的全面了解，包括基础性的定义、支持基础性响应的技术、验证和改进这些响应的方法。通过这些课程笔记，学习者可以更好地理解如何提高LLM在各种应用中的性能和可信度。