# Lecture9

这份PPT是关于如何使用影响函数（Influence Functions）来研究大型语言模型（LLM）的泛化能力的讨论，由Roger Grosse、Juhan Bae、Cem Anil等人在斯坦福大学的CS329T课程中进行。以下是对PPT内容的详细解释和分析，以及相应的课程笔记。

### 1. 动机
- **问题**：如何解释大型语言模型（LLM）出人意料的行为？
- **挑战**：模型的随机性和生成样本的多种可能假设使得直接检查样本来解释行为变得困难。

### 2. 解释LLM行为的方法
- **机制解释性**：自底向上的方法，需要完整解释计算过程，但可能不总是可行。
- **影响函数**：自顶向下的方法，检查训练样本对模型行为的影响。

### 3. 影响函数的概念
- **统计学中的经典概念**：用于理解添加新训练样本对模型的影响。
- **计算**：使用隐函数定理和链式法则来计算损失函数的变化。

### 4. 影响函数的挑战
- **概念挑战**：传统影响函数不完全适用于现代神经网络，因为它们假设了模型的可逆性和最优解的存在。
- **可扩展性挑战**：对于大型模型，影响函数的计算涉及到的逆海森矩阵（inverse-Hessian）的维度是模型参数的数量，这使得直接计算变得不可能。

### 5. 影响函数的可扩展性解决方案
- **Kronecker-Factored Approximate Curvature (K-FAC)**：一种用于优化的参数化近似方法，可以扩展到其他任务。
- **Eigenvalue-Corrected K-FAC (EK-FAC)**：一种更健壮的扩展，可以有效地计算大型模型上的影响函数。

### 6. 影响函数的准确性
- **与Proximal Bregman Response Function (PBRF)的相关性**：PBRF是一种计算成本高昂的基准，用于评估影响函数近似的准确性。

### 7. LLM中的影响函数
- **目标**：确定哪些训练序列对给定提示和完成的响应有显著影响。
- **计算方法**：首先计算对特定查询的影响，然后计算所有候选训练序列的影响。

### 8. 数据过滤和查询批处理
- **数据过滤**：使用TF-IDF选择候选训练序列，以减少需要计算梯度的序列数量。
- **查询批处理**：通过预先计算训练梯度并重用它们，避免对每个查询重复计算。

### 9. 影响分布
- **模型大小**：随着模型大小的增加，泛化模式变得更加复杂和抽象。

### 10. 跨语言泛化
- **现象**：LLM在不同语言之间展现出泛化能力。

### 11. 定位到层和令牌
- **技术**：可以将影响归因于个体令牌和层。
- **令牌级影响**：通过测量与该令牌相关的梯度项来影响损失。

### 12. 词序问题
- **观察**：LLM对词序的敏感性。
- **实验操作**：通过合成“训练”序列来研究泛化模式。

### 13. 未来方向
- **影响函数**：分析LLM中的高级认知现象。
- **自我概念**：AI在训练集中的描述是否形成AI助手自我概念的核心部分？
- **表示定位**：使用影响函数来定位真理/虚假等的表示。
- **预训练与微调的交互**：微调的泛化模式受优化器隐含偏差的支配，这种偏差来自于预训练期间学习的关联。

### 课程笔记总结
- **LLM行为解释**：了解如何使用影响函数来解释LLM的意外行为。
- **影响函数基础**：学习影响函数的统计学基础和在深度学习中的引入。
- **挑战**：认识到影响函数在现代神经网络中的概念和可扩展性挑战。
- **解决方案**：探索K-FAC和EK-FAC等方法来克服可扩展性挑战。
- **准确性评估**：了解如何通过与PBRF的相关性来评估影响函数的准确性。
- **LLM中的影响**：学习如何确定对LLM响应有显著影响的训练序列。
- **数据过滤和批处理**：了解如何使用这些技术来提高计算效率。
- **影响分布**：观察模型大小对泛化模式的影响。
- **跨语言泛化**：探索LLM在不同语言之间的泛化能力。
- **定位技术**：学习如何将影响归因于个体令牌和层。
- **词序问题**：研究LLM对词序的敏感性及其对泛化的影响。
- **未来方向**：了解影响函数在分析LLM中的高级应用和潜在的研究方向。

这份PPT提供了对使用影响函数分析大型语言模型的全面了解，包括它们的挑战、解决方案、应用和未来研究方向。通过这些课程笔记，学习者可以更好地理解如何使用影响函数来研究和解释LLM的行为。