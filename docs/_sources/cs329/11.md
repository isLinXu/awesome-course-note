# Lecture11

这份文档是关于“可信机器学习：大型语言模型及应用”的课程，第11讲的PDF笔记，由Roger Grosse, Juhan Bae, Cem Anil等人在Anthropic研究所进行的研究。以下是对文档内容的详细解释和分析：

### 1. 动机
- **问题**: 如何解释大型语言模型（LLMs）的意外行为？
- **挑战**: 模型的随机性和生成样本的多种可能假设使得直接检查样本难以发现模型之间的微小差异。

### 2. 解释方法
- **机制解释性**: 从底层方法解释，需要完整解释计算过程，但可能不可行。
- **影响函数**: 从顶层方法出发，检查训练样本对模型行为的影响。

### 3. 影响函数（Influence Functions）
- **起源**: 来自统计学的经典概念，后被引入深度学习。
- **目的**: 了解添加新的训练样本对模型参数的影响。
- **计算**: 使用隐函数定理和链式法则计算训练数据点对测试数据点损失的影响。

### 4. 影响函数的挑战
- **概念挑战**: 传统影响函数不完全适用于现代神经网络，因为它们假设模型是可逆的，而神经网络训练通常是欠规范的。
- **可扩展性挑战**: 影响函数的计算需要逆海森矩阵-向量乘积（IHVP），对于大型模型无法显式计算。

### 5. Kronecker-Factored Approximate Curvature (K-FAC)
- **方法**: 用于优化的神经网络海森矩阵的参数化近似，后扩展到其他任务。
- **优势**: 通过EK-FAC，我们可以高效地计算大型模型上的影响函数。

### 6. 影响函数的准确性
- **评估**: 使用与Proximal Bregman Response Function (PBRF)的Spearman相关性来评估EK-FAC的准确性。

### 7. LLMs的影响函数
- **目标**: 确定哪些训练序列对给定提示和完成的模型有显著影响。
- **计算**: 首先计算影响函数，然后对所有候选训练序列计算梯度。

### 8. 数据过滤和查询批处理
- **数据过滤**: 使用TF-IDF选择候选训练序列，以减少需要计算梯度的序列数量。
- **查询批处理**: 通过低秩近似和批量运行查询来提高计算效率。

### 9. 影响分布
- **发现**: 随着模型大小的增加，模型的泛化模式变得更加复杂和抽象。

### 10. 跨语言泛化
- **观察**: 模型在跨语言任务中表现出泛化能力。

### 11. 定位到层和令牌
- **技术**: 将影响归因于个体令牌和层。
- **挑战**: 令牌层面的影响难以捉摸，因为改变一个令牌可能会影响序列中前后令牌的激活。

### 12. 词序问题
- **观察**: 模型对词序的敏感性。
- **实验操作**: 使用合成“训练”序列来研究泛化模式。

### 13. 未来方向
- **工具**: 影响函数是分析LLMs中高级认知现象的少数工具之一。
- **研究问题**: 训练集中对AI的描述是否形成了AI助手的自我概念的核心部分？
- **应用**: 使用影响函数来定位表示（例如，真理/虚假）。
- **理解交互**: 预训练和微调之间的交互，以及微调的泛化模式如何受到预训练期间学习到的关联的影响。

这份笔记为听众提供了关于如何使用影响函数来分析和解释大型语言模型的行为的深入分析，并探讨了当前的挑战和潜在的研究方向。通过这些内容，听众可以更好地理解LLMs在处理复杂任务时的内部机制和泛化能力。