这份PPT是关于生成性人工智能（Generative AI）的课程内容，具体讲解了视觉变换器（Vision Transformers，简称ViT）和生成对抗网络（Generative Adversarial Networks，简称GANs）。以下是根据PPT内容编写的详细课程笔记：

### 1. 课程提醒
- **作业1**：关于文本的生成模型，已经发布并有截止日期。

### 2. 预训练是否总是涉及逐层无监督训练？
- 预训练并不总是涉及逐层无监督训练。对于CNN或视觉变换器，我们通常在监督分类问题（即图像分类）上训练整个模型。对于大型语言模型（LLM），我们通常在未标记句子的似然性上训练整个模型。

### 3. 旋转位置嵌入（Rotary Position Embeddings, RoPE）
- RoPE是一种相对位置嵌入，它将每个d维输入向量分成d/2个长度为2的向量，并通过由m（查询或键的绝对位置）缩放的量来旋转这些向量。

### 4. 计算机视觉中的常见任务
- 包括图像分类、图像分类+定位、人体姿态估计、语义分割、目标检测、实例分割、图像字幕和图像生成。

### 5. 变换器（Transformer）模型
- 自回归语言模型定义了一种概率分布，其中每个词都依赖于前面的词。
- 编码器仅变换器（Encoder-only Transformer）使用非因果注意力机制，而BERT模型通过遮蔽语言模型（Masked Language Model, MLM）预训练来训练这种架构。

### 6. 视觉变换器（Vision Transformer, ViT）
- ViT模型与BERT几乎相同，但输入是PxP像素图像块，而不是词。每个像素块被线性嵌入到一个固定大小的向量中。
- 预训练时，ViT在大型监督数据集上进行图像分类优化；微调时，在小型数据集上学习新的分类头部。

### 7. 图像生成任务
- 图像生成包括类条件生成、超分辨率、图像编辑、风格迁移和文本到图像（Text-to-Image, TTI）生成。

### 8. 生成对抗网络（GANs）
- GANs由两个确定性神经网络模型组成：生成器（Generator）和判别器（Discriminator）。
- 生成器接收随机噪声向量作为输入并生成图像；判别器接收图像并分类它为真（标签1）或假（标签0）。
- 在训练中，GAN进行两人最小最大游戏：生成器尝试创建逼真的图像以欺骗判别器认为它们是真实的；判别器试图从假的图像中识别真实的图像。

### 9. 学习GANs
- GANs的训练涉及交替进行：保持生成器固定并通过判别器进行反向传播；保持判别器固定并通过生成器进行反向传播。

### 10. 扩大模型规模
- 通过增加模型大小，可以提高生成图像的质量。例如，Parti模型将图像生成视为序列到序列问题，使用ViT-VQGAN生成高质量图像。

### 11. 水印和归属
- 水印：允许识别模型创建的图像。
- 假图像检测：即使没有水印，也试图识别假图像。
- 模型归属：确定生成图像的生成模型（例如，Dalle-2与SDXL）。
- 图像归属：确定导致新图像生成的源图像，这是一个极具挑战性的任务。

### 12. 图像生成的社会影响
- 图像生成的正面影响包括为艺术家提供新工具和加快模因的创造。
- 负面影响包括侵犯版权、艺术家工作机会的减少、社会创造力的降低、创造非人道内容的潜力、假新闻/虚假现实/事实核查难度增加以及与现实脱节。

这些笔记概括了PPT中的主要概念和生成性人工智能在视觉领域的应用，可以作为学习和理解生成性人工智能课程内容的基础。如果你对某个特定部分有疑问或需要更深入的解释，请随时提问。