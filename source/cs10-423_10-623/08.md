这份PPT是关于生成性人工智能（Generative AI）的课程内容，具体讲解了扩散模型（Diffusion Models）。以下是根据PPT内容编写的详细课程笔记：

### 1. 课程提醒
- **作业2**：关于图像的生成模型，已经发布并有截止日期。

### 2. U-Net 架构
- U-Net是一种用于图像分割的网络，它包含收缩路径和扩展路径，通过卷积层、ReLU激活函数和最大池化进行下采样，然后通过上采样、特征拼接和卷积层进行上采样。

### 3. 无监督学习
- 无监督学习的假设包括数据来自某个分布q(x0)，我们选择一个易于采样的分布pθ(x0)。
- 目标是学习θ，使得pθ(x0)接近q(x0)。

### 4. KL散度（KL Divergence）
- KL散度是衡量两个概率分布q和p接近程度的指标，不具有对称性，当q(x) = p(x)时，KL散度最小。

### 5. 扩散模型（Diffusion Models）
- 扩散模型是一种生成模型，它通过定义涉及高斯噪声的概率分布，并使用变分下界作为目标函数来学习概率分布的参数。

### 6. 扩散模型的前向过程和反向过程
- 前向过程（Learned）是通过添加噪声来逐渐将数据分布q(x0)转换成高斯分布的过程。
- 反向过程（Exact）是去除噪声，恢复数据的过程，这个过程需要推断，并且是不可计算的。

### 7. 扩散模型的参数化
- 扩散模型的参数化涉及到如何近似q(xt−1 | xt, x0)，这是通过不同的方法来实现的，包括使用U-Net网络。

### 8. 扩散模型的训练
- 根据参数化的选择，可以得到不同的训练算法。训练目标是使得学习到的反向过程尽可能接近于真实的反向过程。

### 9. 扩散模型的采样
- 采样过程是从高斯分布pθ(xT)开始，逐步通过反向过程生成x0。

### 10. 扩散模型的目标函数
- 扩散模型的训练涉及到最小化两个条件分布之间的KL散度，这是一个变分下界。

### 11. 变分扩散模型与变分自编码器（VAEs）
- 虽然VAEs先出现，但课程将更多关注扩散模型。
- 定义这些模型的步骤大致包括：定义涉及高斯噪声的概率分布，使用变分下界作为目标函数，通过优化目标函数来学习概率分布的参数。

这些笔记概括了PPT中的主要概念和生成性人工智能在图像生成领域的应用，可以作为学习和理解生成性人工智能课程内容的基础。如果你对某个特定部分有疑问或需要更深入的解释，请随时提问。