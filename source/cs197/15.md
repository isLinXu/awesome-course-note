# Lecture21

这份文档是哈佛大学CS197课程第21讲的笔记，主题为“模型对决：比较模型性能的统计测试”。以下是对文档内容的详细解释和分析：

### 1. 摘要

- **主题**: 讨论了在相同测试集上比较两个机器学习模型性能的统计测试方法。
- **内容**: 包括McNemar测试、配对t检验和自举方法（bootstrap method），并提供了Python实现示例。

### 2. 学习成果

- **理解统计测试**: 用于比较机器学习模型的不同统计测试。
- **实现统计测试**: 使用Python评估两个模型在相同测试集上的性能。
- **选择适当测试**: 根据研究问题选择适当的测试，包括优越性、非劣性和等效性测试。

### 3. 统计测试

- **目的**: 确定模型性能差异是否显著，或者是否可能由偶然因素引起。
- **假设**: 形成零假设（H0）和备择假设（H1），零假设通常表示两个模型性能没有差异。

### 4. McNemar测试

- **用途**: 用于比较两个二分类模型在同一数据集上的性能。
- **基础**: 基于比较两个模型正确和错误预测数量的列联表。
- **统计量**: 使用卡方统计量来评估两个模型准确度的差异。

### 5. 配对t检验

- **用途**: 比较两个相关样本的平均值，确定它们是否显著不同。
- **相关样本**: 如果两个样本在同一测试集或以某种方式相关的数据集上被评估，则被认为是相关的。

### 6. 自举方法（Bootstrap）

- **定义**: 一种统计技术，通过从原始样本数据中有放回地生成多个重采样来估计统计量的抽样分布。
- **应用**: 当其他统计测试的假设不满足时，如数据不正态分布或样本量小，自举方法特别有用。

### 7. 选择适当的统计测试

- **研究问题**: 在选择比较两个机器学习模型性能的适当统计测试时，需要明确研究问题和期望的结果。
- **优越性测试**: 确定一个模型是否在性能上显著优于另一个模型。
- **非劣性测试**: 确定一个模型是否在性能上不显著劣于另一个模型。
- **等效性测试**: 确定两个模型在性能上是否等效。

### 8. 家庭作业

- **练习1**: 使用BLEU分数比较两个报告生成模型的性能。
- **练习2**: 证明你的模型在CheXPert基准测试上的改进不太可能是由于随机机会。
- **练习3**: 检查你的模型是否比病理学家在诊断淋巴瘤亚型方面表现得更好或至少不差。

### 9. 置信区间

- **定义**: 提供一个值范围，这个范围很可能包含真实总体参数，基于用于训练模型的样本数据。
- **作用**: 帮助我们更好地理解模型性能的变异性，并通过报告模型性能的置信区间，了解模型的可靠性及其预测的不确定性。

### 10. 结论

- **总结**: 探讨了创建有效幻灯片的各种策略，包括断言-证据方法，避免常见错误，以及如何使文本更简洁有序。强调了设计元素和幻灯片页脚的重要性。

这份笔记为机器学习研究者提供了如何在统计上比较两个模型性能的实用指导，强调了选择合适的统计测试和解释结果的重要性。通过应用这些技巧，研究者可以更准确地评估模型性能，并做出更有信息量的决策。